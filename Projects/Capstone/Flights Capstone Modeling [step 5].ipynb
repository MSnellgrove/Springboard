{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5830e183",
   "metadata": {},
   "source": [
    "# Flights Capstone Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db90fb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/13/94/f73d4efcc9a0272ea9f93c03f4744a2b709172309cd0bfde1e9012776330/xgboost-2.0.1-py3-none-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading xgboost-2.0.1-py3-none-macosx_12_0_arm64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /Users/morgansnellgrove/anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/morgansnellgrove/anaconda3/lib/python3.11/site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.1-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab43c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f519033",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.read_csv('flights_X_train_scaled.csv', index_col = 0)\n",
    "X_test_scaled = pd.read_csv('flights_X_test_scaled.csv', index_col = 0)\n",
    "y_train = pd.read_csv('flights_y_train.csv', index_col = 0)\n",
    "y_test = pd.read_csv('flights_y_test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24872d4",
   "metadata": {},
   "source": [
    "# Dummy Regressor\n",
    "## What if we just guess the mean? \n",
    "\n",
    "Baseline to compare with later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d459353f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_usd    255.485841\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mean = y_train.mean()\n",
    "y_train_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9bfb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255.48584134]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_reg = DummyRegressor(strategy = 'mean')\n",
    "dum_reg.fit(X_train_scaled, y_train)\n",
    "dum_reg.constant_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e7c88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255.48584134, 255.48584134, 255.48584134, ..., 255.48584134,\n",
       "       255.48584134, 255.48584134])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = dum_reg.predict(X_train_scaled)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52480547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_reg.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45037ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.5818853610637404e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_reg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46027c",
   "metadata": {},
   "source": [
    "## Metrics for the Dummy Regressor\n",
    "\n",
    "As expected this would be a terrible way to predict ticket price. Here are all of the common metrics for this dummy regressor model. We can use these values to guage how much better our other models are than this dummy model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4641062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = dum_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e558e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -2.5818853610637404e-06)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b273aabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241.68521330855492, 241.47284821915693)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b16e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77102.76711131452, 76792.4956587832)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38be1780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277.6738502475783, 277.1145894008166)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred, squared = False), mean_squared_error(y_test, y_test_pred, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26f683",
   "metadata": {},
   "source": [
    "# Linear Regression Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa747e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9f8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "y_train_pred_lin = lin_reg.predict(X_train_scaled)\n",
    "y_test_pred_lin = lin_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378ac8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9254824492306011, -1.3165964551481275e+20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred_lin), r2_score(y_test, y_test_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552f5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51.38056278820564, 15715810684.837727)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_pred_lin), mean_absolute_error(y_test, y_test_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e93cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5745.509362678522, 1.0110446652618985e+25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred_lin), mean_squared_error(y_test, y_test_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4d0834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.79913827134529, 3179692855075.626)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred_lin, squared = False), mean_squared_error(y_test, y_test_pred_lin, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb5068",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "The scores for the test set are worse than the scores in the dummy regressor, but training scores improved. This is definitely not our model. In the guided capstone they use SelectKBest to subset the features used and hopefully improve the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fb09a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(SelectKBest(f_regression), LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22623cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225195, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8acf8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;selectkbest&#x27;,\n",
       "                 SelectKBest(score_func=&lt;function f_regression at 0x169127c40&gt;)),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;selectkbest&#x27;,\n",
       "                 SelectKBest(score_func=&lt;function f_regression at 0x169127c40&gt;)),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(score_func=&lt;function f_regression at 0x169127c40&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('selectkbest',\n",
       "                 SelectKBest(score_func=<function f_regression at 0x169127c40>)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train_scaled, y_train.price_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e7754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_lin = pipe.predict(X_train_scaled)\n",
    "y_test_pred_lin = pipe.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "587f8bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9061065842786092, 0.9062376038300555)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred_lin), r2_score(y_test, y_test_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a87c88f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.785391049912924, 55.570766223643034)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_pred_lin), mean_absolute_error(y_test, y_test_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d98579bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7239.442165652228, 7200.229810669629)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred_lin), mean_squared_error(y_test, y_test_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53482fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.08491150405122, 84.85416790393757)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred_lin, squared = False), mean_squared_error(y_test, y_test_pred_lin, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1adb9",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "These scores are much better. Maybe we should include SelectKBest with other models as well. I was surprised that the scores for the test data are actually slightly better than the scores for the training data...I'm not sure why that would be. We could try setting the value for k, but I'll wait and see how other models perform first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362d17fa",
   "metadata": {},
   "source": [
    "# Lasso and Ridge Models\n",
    "\n",
    "Next I wanted to try a Lasso and Ridge modles, but we need to pick values for alpha. I'm going to test out some different values to see how they change the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6029d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = []\n",
    "for alpha in [1, 5, 10, 20]:\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    y_pred = lasso.predict(X_test_scaled)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    lasso_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d732b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9199797921974991, 0.9060540930116233, 0.901156052794979, 0.8879319119850346]\n"
     ]
    }
   ],
   "source": [
    "print(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62fcc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for alpha in [10, 50, 100, 1000]:\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    y_pred = ridge.predict(X_test_scaled)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02433c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9246842784907655, 0.9246849807932151, 0.9246854883857387, 0.9246661032874668]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63aa0a7",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "My best scores were Lasso(alpha = 1) and Ridge(alpha = 100). If one of these wind up being our best model, I'll run CV to select alpha. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851ddaf",
   "metadata": {},
   "source": [
    "# Random Forest Model\n",
    "\n",
    "Next I wanted to try RandomForestRegressor. First I'll try it with the default settings to see what we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e962c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9905783194859459\n",
      "Execution time in seconds: 750.976350069046\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train_scaled, y_train.price_usd)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "score = r2_score(y_test, y_pred_rf)\n",
    "print(score)\n",
    "executionTime = (time.time() - start)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87a355c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.062227260595428"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "791fe1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.898187521608733"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rf, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2139c8",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "These are really high scores. This is the best model so far. I wonder if it's overfitting or if I should mess with parameter settings? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd773b21",
   "metadata": {},
   "source": [
    "# XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c487260",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70183e70",
   "metadata": {},
   "source": [
    "### Tree Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c53e6e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771675993941723\n",
      "Execution time in seconds: 11.939765930175781\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xg_reg = XGBRegressor(objective = 'reg:squarederror')\n",
    "xg_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_xg = xg_reg.predict(X_test_scaled)\n",
    "score = r2_score(y_test, y_pred_xg)\n",
    "print(score)\n",
    "executionTime = (time.time() - start)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db8b00ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.216309484062002"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8233cee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.87305216302573"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_xg, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f63a5",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "This is much fast than the Random Forest Model, but the scores are not as good. Maybe tuning will improve the scores. I also want to try XGBoost with linear base learners. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd4165",
   "metadata": {},
   "source": [
    "### Linear Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d73510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9243776169041054\n",
      "Execution time in seconds: 29.132174730300903\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "DM_train = xgb.DMatrix(data = X_train_scaled, label = y_train)\n",
    "DM_test = xgb.DMatrix(data = X_test_scaled, label = y_test)\n",
    "params = {'booster':'gblinear', 'objective':'reg:squarederror'}\n",
    "xg_reg = xgb.train(params = params, dtrain = DM_train)\n",
    "preds = xg_reg.predict(DM_test)\n",
    "score = r2_score(y_test, preds)\n",
    "print(score)\n",
    "executionTime = (time.time() - start)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7dd502d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.384494647561866"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4dd2ba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.20509518418682"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, preds, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a0cc6",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "The error increased with linear base learners. I think the tree base learners are a better choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef3e0d",
   "metadata": {},
   "source": [
    "# Best Model Selection\n",
    "\n",
    "Our best model is the Random Forest Model. A close second is the XGBoost tree based model. The XGBoost model was much faster, but had higher error. \n",
    "\n",
    "It took over 12 minutes to train and make predictions with one RF model. Doing CV will take a long time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
